{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense #全连接层\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create some data\n",
    "X = np.linspace(-1, 1, 200)\n",
    "np.random.shuffle(X)    # randomize the data\n",
    "Y = 0.5 * X + 2 + np.random.normal(0, 0.05, (200, ))\n",
    "# plot data\n",
    "plt.scatter(X, Y)\n",
    "plt.show()\n",
    "\n",
    "X_train, Y_train = X[:160], Y[:160]     # first 160 data points\n",
    "X_test, Y_test = X[160:], Y[160:]       # last 40 data points\n",
    "\n",
    "# build a neural network from the 1st layer to the last layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=1, input_dim=1)) #input_dim表示输入,out\n",
    "\n",
    "# choose loss function and optimizing method\n",
    "model.compile(loss='mse', optimizer='sgd')\n",
    "\n",
    "# training\n",
    "print('Training -----------')\n",
    "for step in range(301):\n",
    "    cost = model.train_on_batch(X_train, Y_train)\n",
    "    if step % 100 == 0:\n",
    "        print('train cost: ', cost)\n",
    "\n",
    "# test\n",
    "print('\\nTesting ------------')\n",
    "cost = model.evaluate(X_test, Y_test, batch_size=40)\n",
    "print('test cost:', cost)\n",
    "W, b = model.layers[0].get_weights()\n",
    "print('Weights=', W, '\\nbiases=', b)\n",
    "\n",
    "# plotting the prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "fig = plt.figure()\n",
    "plt.scatter(X_test, Y_test)\n",
    "plt.plot(X_test, Y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 - Classifier example\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called\n",
    "# X shape (60,000 28x28), y shape (10,000, )\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# data pre-processing\n",
    "X_train = X_train.reshape(X_train.shape[0], -1) / 255.   # normalize\n",
    "X_test = X_test.reshape(X_test.shape[0], -1) / 255.      # normalize\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Another way to build your neural net\n",
    "model = Sequential([\n",
    "    Dense(32, input_dim=784),\n",
    "    Activation('relu'),\n",
    "    Dense(64),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "# Another way to define your optimizer\n",
    "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# We add metrics to get more results you want to see\n",
    "model.compile(optimizer=rmsprop,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Training ------------')\n",
    "# Another way to train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "print('\\nTesting ------------')\n",
    "# Evaluate the model with the metrics we defined earlier\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called\n",
    "# training X shape (60000, 28x28), Y shape (60000, ). test X shape (10000, 28x28), Y shape (10000, )\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 1,28, 28)/255.\n",
    "X_test = X_test.reshape(-1, 1,28, 28)/255.\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Another way to build your CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Conv layer 1 output shape (32, 28, 28)\n",
    "model.add(Convolution2D(\n",
    "    batch_input_shape=(None, 1, 28, 28),\n",
    "    filters=32,\n",
    "    kernel_size=5,\n",
    "    strides=1,\n",
    "    padding='same',     # Padding method\n",
    "    data_format='channels_first',\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling layer 1 (max pooling) output shape (32, 14, 14)\n",
    "model.add(MaxPooling2D(\n",
    "    pool_size=2,\n",
    "    strides=2,\n",
    "    padding='same',    # Padding method\n",
    "    data_format='channels_first',\n",
    "))\n",
    "\n",
    "# Conv layer 2 output shape (64, 14, 14)\n",
    "model.add(Convolution2D(64, 5, strides=1, padding='same', data_format='channels_first'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling layer 2 (max pooling) output shape (64, 7, 7)\n",
    "model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))\n",
    "\n",
    "# Fully connected layer 1 input shape (64 * 7 * 7) = (3136), output shape (1024)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Fully connected layer 2 to shape (10) for 10 classes\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Another way to define your optimizer\n",
    "adam = Adam(lr=1e-4)\n",
    "\n",
    "# We add metrics to get more results you want to see\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Training ------------')\n",
    "# Another way to train the model\n",
    "model.fit(X_train, y_train, epochs=1, batch_size=64,)\n",
    "\n",
    "print('\\nTesting ------------')\n",
    "# Evaluate the model with the metrics we defined earlier\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
